{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d87ecd0-e95e-47f5-8108-f03146be0e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import unicodedata\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c207a-00c8-435f-9be2-f1381820e864",
   "metadata": {},
   "source": [
    "# Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "\n",
    "    - Lowercase everything\n",
    "    - Normalize unicode characters\n",
    "    - Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e426f-96f8-4d4a-8312-23a8f288f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    # Lowercase everything\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Normalize unicode characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "    text = re.sub(r\"[^a-z0-9'\\s]\", '', text)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966b4bca-c43f-4493-9da6-05bdcd1193ca",
   "metadata": {},
   "source": [
    "# Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d7f32-4965-477f-a633-6f3024a11387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Clean the text first\n",
    "    clean_text = basic_clean(text)\n",
    "    \n",
    "    # Then tokenize it\n",
    "    tokens = nltk.word_tokenize(clean_text)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f37d8eb-1b39-441f-ae07-6e58fd1f22cb",
   "metadata": {},
   "source": [
    "# Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617bba4b-9346-46bc-8c09-d7a2b60b9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(text):\n",
    "    # Instantiate the stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Apply stemming to each token\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "    \n",
    "    # Join the stemmed tokens back into a single string\n",
    "    stemmed_text = ' '.join(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4782533b-257a-4448-a7be-e942a65910cc",
   "metadata": {},
   "source": [
    "# Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2435d793-4dcd-4070-ab0d-ed5b57d48554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemmatize(text):\n",
    "    # Instantiate the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Tokenize the input text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Apply lemmatization to each token\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    # Join the lemmatized tokens back into a single string\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return lemmatized_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b8b423-d4b4-4440-9673-a7c5b6ca9ad0",
   "metadata": {},
   "source": [
    "# Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "    This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4ec16-4ca6-4cf0-ae50-b62005cdf0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def remove_stopwords(text, extra_words=None, exclude_words=None):\n",
    "    # Get the list of English stopwords\n",
    "    stopword_list = stopwords.words('english')\n",
    "\n",
    "    # Add extra_words to the stopword list, if provided\n",
    "    if extra_words:\n",
    "        stopword_list.extend(extra_words)\n",
    "\n",
    "    # Remove exclude_words from the stopword list, if provided\n",
    "    if exclude_words:\n",
    "        stopword_list = [word for word in stopword_list if word not in exclude_words]\n",
    "\n",
    "    # Tokenize the input text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords from the tokens\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "\n",
    "    # Join the filtered tokens back into a single string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return filtered_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f0406-e72b-422f-8bf6-ea722745005a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
